ninja_required_version = 1.3
cxx = cl
nvcc = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3\bin\nvcc

cflags = -DTORCH_EXTENSION_NAME=_slangpy_square_44136fa355b3678a -DTORCH_API_INCLUDE_EXTENSION_H -IC:\Users\David\code_projects\tinynerf\slang -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include\torch\csrc\api\include -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include\TH -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include\THC "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3\include" -IC:\Users\David\miniconda3\envs\tinynerf-env\Include -D_GLIBCXX_USE_CXX11_ABI=0 /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc /std:c++17 /std:c++17
post_cflags = 
cuda_cflags = -Xcudafe --diag_suppress=dll_interface_conflict_dllexport_assumed -Xcudafe --diag_suppress=dll_interface_conflict_none_assumed -Xcudafe --diag_suppress=field_without_dll_interface -Xcudafe --diag_suppress=base_class_has_different_dll_interface -Xcompiler /EHsc -Xcompiler /wd4068 -Xcompiler /wd4067 -Xcompiler /wd4624 -Xcompiler /wd4190 -Xcompiler /wd4018 -Xcompiler /wd4275 -Xcompiler /wd4267 -Xcompiler /wd4244 -Xcompiler /wd4251 -Xcompiler /wd4819 -Xcompiler /MD -DTORCH_EXTENSION_NAME=_slangpy_square_44136fa355b3678a -DTORCH_API_INCLUDE_EXTENSION_H -IC:\Users\David\code_projects\tinynerf\slang -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include\torch\csrc\api\include -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include\TH -IC:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\include\THC "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3\include" -IC:\Users\David\miniconda3\envs\tinynerf-env\Include -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_52,code=compute_52 -gencode=arch=compute_52,code=sm_52 -std=c++17 --std=c++17
cuda_post_cflags = 
cuda_dlink_post_cflags = 
ldflags = /DLL c10.lib c10_cuda.lib torch_cpu.lib torch_cuda.lib -INCLUDE:?warp_size@cuda@at@@YAHXZ torch.lib /LIBPATH:C:\Users\David\miniconda3\envs\tinynerf-env\Lib\site-packages\torch\lib torch_python.lib /LIBPATH:C:\Users\David\miniconda3\envs\tinynerf-env\libs "/LIBPATH:C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.3\lib\x64" cudart.lib

rule compile
  command = cl /showIncludes $cflags -c $in /Fo$out $post_cflags
  deps = msvc

rule cuda_compile
  depfile = $out.d
  deps = gcc
  command = $nvcc --generate-dependencies-with-compile --dependency-output $out.d $cuda_cflags -c $in -o $out $cuda_post_cflags



rule link
  command = "C$:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.38.33130\bin\Hostx64\x64/link.exe" $in /nologo $ldflags /out:$out

build square.o: compile C$:\Users\David\code_projects\tinynerf\slang\.slangpy_cache\square\44136fa355b3678a\square.cpp
build square_cuda.cuda.o: cuda_compile C$:\Users\David\code_projects\tinynerf\slang\.slangpy_cache\square\44136fa355b3678a\square_cuda.cu



build _slangpy_square_44136fa355b3678a.pyd: link square.o square_cuda.cuda.o

default _slangpy_square_44136fa355b3678a.pyd
